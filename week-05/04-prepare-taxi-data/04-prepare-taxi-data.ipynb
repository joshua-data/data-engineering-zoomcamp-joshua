{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Write file with Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "years = [2023, 2024]\n",
    "taxi_types = ['yellow', 'green']\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    if year == 2023:\n",
    "        months = range(1, 13) # Month 1 - 12\n",
    "    elif year == 2024:\n",
    "        months = range(1, 12) # Month 1 - 11    \n",
    "    \n",
    "    for taxi_type in taxi_types:\n",
    "        \n",
    "        for month in months:\n",
    "\n",
    "            print(f'Processing Data for {year}/{month}...')\n",
    "\n",
    "            input_folderpath = f'data/raw/{taxi_type}/{year}/{month:02d}/'\n",
    "            output_folderpath = f'data/pq/{taxi_type}/{year}/{month:02d}/'\n",
    "            \n",
    "            df = spark.read \\\n",
    "                .option('header', 'true') \\\n",
    "                .parquet(input_folderpath)\n",
    "            \n",
    "            df.repartition(4) \\\n",
    "                .write.parquet(output_folderpath)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
